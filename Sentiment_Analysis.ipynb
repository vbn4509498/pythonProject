{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd0mtr/mD0viNzhw8hCUay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbn4509498/pythonProject/blob/Tensorflow/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s58it2soKjD",
        "outputId": "2759d77a-cdc3-4ed8-c263-9bf60716fe28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
            "x_test shape: (25000, 80)\n",
            "Epoch 1/4\n",
            "195/195 [==============================] - 28s 96ms/step - loss: 0.5329 - accuracy: 0.7067 - val_loss: 0.4195 - val_accuracy: 0.8177\n",
            "Epoch 2/4\n",
            "195/195 [==============================] - 19s 97ms/step - loss: 0.3247 - accuracy: 0.8645 - val_loss: 0.3958 - val_accuracy: 0.8334\n",
            "Epoch 3/4\n",
            "195/195 [==============================] - 19s 98ms/step - loss: 0.2022 - accuracy: 0.9231 - val_loss: 0.5161 - val_accuracy: 0.8180\n",
            "Epoch 4/4\n",
            "195/195 [==============================] - 19s 98ms/step - loss: 0.1155 - accuracy: 0.9581 - val_loss: 0.5998 - val_accuracy: 0.8083\n",
            "195/195 [==============================] - 3s 18ms/step - loss: 0.5998 - accuracy: 0.8083\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "tf.random.set_seed(22)\n",
        "np.random.seed(22)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "assert tf.__version__.startswith('2.')\n",
        "# the most frequence words\n",
        "total_words = 10000\n",
        "max_review_len = 80\n",
        "embedding_len = 100\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.imdb.load_data(num_words=total_words)\n",
        "# 縮減句子長度至80(80個單字一個句子)\n",
        "# x_train:[b,80] number\n",
        "# x_test:[b,80]\n",
        "x_train = tf.keras.utils.pad_sequences(x_train,maxlen = max_review_len)\n",
        "x_test = tf.keras.utils.pad_sequences(x_test,maxlen = max_review_len)\n",
        "\n",
        "batchsz = 128\n",
        "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "db_train = db_train.shuffle(1000).batch(batchsz,drop_remainder=True) #drop_remainder 把最後一個batch drop掉\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
        "db_test = db_test.batch(batchsz,drop_remainder=True)\n",
        "print('x_train shape:',x_train.shape,tf.reduce_max(y_train),tf.reduce_min(y_train))\n",
        "print('x_test shape:',x_test.shape)\n",
        "\n",
        "\n",
        "class MyRnn(keras.Model):\n",
        "\n",
        "  def __init__(self,units):\n",
        "    super(MyRnn,self).__init__()\n",
        "    #[b,64]\n",
        "    self.state=[tf.zeros([batchsz,units])]\n",
        "    self.state1=[tf.zeros([batchsz,units])]\n",
        "    # transform text to embedding representation\n",
        "    # [b,80] => [b,80,100]\n",
        "    self.embedding = layers.Embedding(total_words,embedding_len,input_length=max_review_len)\n",
        "\n",
        "    #[b,80,100] => hid_dim:64\n",
        "    #RNN:cell1,cell2,cell3\n",
        "    #SimpleRnn\n",
        "    self.rnn_cell = layers.SimpleRNNCell(units,dropout=0.2)\n",
        "    self.rnn_cell1 = layers.SimpleRNNCell(units,dropout=0.2)\n",
        "    #fc [b,80,100]=>[b,64] = [b,1]\n",
        "    self.outlayer = layers.Dense(1)\n",
        "\n",
        "\n",
        "  def call(self,inputs,training=None):\n",
        "    \"\"\"\n",
        "    net(x)或net(x,training=True) => train mode\n",
        "    net(x,training=False) =>test mode\n",
        "    :param inputs:[b,80]\n",
        "    :param training:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    #[b,80]\n",
        "    x = inputs\n",
        "    # embedding :[b,80] => [b,80,100]\n",
        "    x=self.embedding(x)\n",
        "    # rnncell compute\n",
        "    # [b,80,100] => [b,64]\n",
        "    state = self.state\n",
        "    state1 = self.state1\n",
        "    for word in tf.unstack(x,axis=1): # word:[b,100 ]\n",
        "      # h1 = x*Wxh + h0 * Whh h1=state1=out\n",
        "      out,state = self.rnn_cell(word,state,training)\n",
        "      out1,state1 = self.rnn_cell1(out,state1,training)\n",
        "    # out:[b,64] => [b,1]\n",
        "    x = self.outlayer(out1)\n",
        "    # p(y is pos|x)\n",
        "    prob = tf.sigmoid(x)\n",
        "    return prob\n",
        "\n",
        "\n",
        "def main():\n",
        "  units = 64\n",
        "  epochs =4\n",
        "  model = MyRnn(units)\n",
        "\n",
        "  model.compile( optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "          loss = tf.losses.BinaryCrossentropy(),\n",
        "          metrics = ['accuracy'])\n",
        "  model.fit(db_train,epochs=epochs,validation_data=db_test)\n",
        "  model.evaluate(db_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ]
}